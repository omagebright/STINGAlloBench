{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; padding:5px; background-color:rgb(252, 253, 255); border: 1px solid lightgrey; padding-left: 1em; padding-right: 1em;\">\n",
    "<img src=\"https://www.cbi.cnptia.embrapa.br/SMS/images/logo_topo_centro_dir.gif\" width=\"180px\" align=\"right\" style=\"padding: 20px\">\n",
    "\n",
    "<a id=\"introduction\"></a>\n",
    "\n",
    "<h1> STINGAlloBench- FB_Omage_etal_2023\n",
    "</h1>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<p  style=\"text-align: justify\">STINGAlloBench: A benchmarking dataset for precise allosteric site prediction using experimentally validated data, tailored for computational biology and machine learning.</p>\n",
    "\n",
    "\n",
    "<br>\n",
    "The steps included in this data analysis and visualisation workflow are: \n",
    "<br>\n",
    "\n",
    "1. <a href=\"#1\">Import Packages</a><br>\n",
    "2. <a href=\"#2\">Load Data & Peak Sheet</a><br>\n",
    "3. <a href=\"#3\">Extract X & Y</a><br>\n",
    "4. <a href=\"#4\">Split Data into Train & Test Set</a><br>\n",
    "5. <a href=\"#5\">Extract, Transform, & Scale X Data with Missing Values Imputed</a><br>\n",
    "6. <a href=\"#6\">Hyperparameter Optimisation</a><br>\n",
    "    6.1. <a href=\"#6.1\">Plot R² & Q²</a><br>\n",
    "    6.2. <a href=\"#6.2\">Plot Latent Projections: Full & CV</a><br>\n",
    "7. <a href=\"#7\">Build Model & Evaluate</a><br>\n",
    "8. <a href=\"#8\">Permutation Test</a><br>\n",
    "9. <a href=\"#9\">Bootstrap Resampling of the Model</a><br> \n",
    "10. <a href=\"#10\">Model Evaluation using Bootstrap Resampling</a><br> \n",
    "11. <a href=\"#11\">Model Visualisation</a><br> \n",
    "    11.1. <a href=\"#11.1\">Plot Latent Projections: in-bag & out-of-bag</a><br>\n",
    "    11.2. <a href=\"#11.2\">Plot Weight Vectors</a><br>\n",
    "12. <a href=\"#12\">Variable Contribution Plots</a><br>  \n",
    "13. <a href=\"#12\">Export Results</a><br>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Import Packages\n",
    "\n",
    "Packages provide additional tools that extend beyond the basic functionality of Python programming. Prior to usage, packages need to be imported into the environment. The following packages need to be imported for this computational workflow:\n",
    "\n",
    "- numpy: A standard package primarily used for the manipulation of arrays.\n",
    "- pandas: A standard package primarily used for the manipulation of data tables.\n",
    "- matplotlib: A standard package primarily used for creating static, animated, and interactive visualizations in Python.\n",
    "- seaborn: A Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\n",
    "- shap: A unified approach to explain the output of any machine learning model.\n",
    "- torch: An open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
    "- platform: A standard Python library to access underlying platform's identifying data.\n",
    "- psutil: A cross-platform library used to access system details and process utilities.\n",
    "- time: A standard Python library for time-related tasks.\n",
    "- warnings: A standard Python library to warn the developer about changes that might affect their program.\n",
    "- sklearn: A standard package with tools for machine learning.\n",
    "- feature_engine: A Python library with multiple feature engineering techniques.\n",
    "- xgboost: An optimized distributed gradient boosting library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:\n",
      "  Number of cores: 40\n",
      "  Number of threads: 80\n",
      "  Architecture: x86_64\n",
      "RAM:\n",
      "  Total: 1081.8 GB\n",
      "All packages successfully loaded\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import psutil\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='darkgrid', font_scale=1.4)\n",
    "\n",
    "# Print CPU information\n",
    "print('CPU:')\n",
    "print(f'  Number of cores: {psutil.cpu_count(logical=False)}')\n",
    "print(f'  Number of threads: {psutil.cpu_count(logical=True)}')\n",
    "print(f'  Architecture: {platform.processor()}')\n",
    "\n",
    "# Print RAM information\n",
    "print('RAM:')\n",
    "print(f'  Total: {psutil.virtual_memory().total / 1e9:.1f} GB')\n",
    "\n",
    "print('All packages successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgb(255, 250, 250); padding:20px;\">\n",
    "\n",
    "<h2>2. Load and Process Training Data</h2>\n",
    "\n",
    "<p>This section outlines the method for loading and processing the training dataset for modeling. It involves reading data from CSV files, cleaning, and preparing it for further analysis. The key steps include verifying and converting data types, merging data frames, and handling missing values. The process is detailed as follows:</p>\n",
    "<ul>\n",
    "    <li><strong>Data Loading:</strong> Training data is loaded from CSV files using <code>pd.read_csv()</code>.</li>\n",
    "    <li><strong>Data Cleaning:</strong> Non-numeric values in 'number' columns are filtered out, and the column is converted to integer type.</li>\n",
    "    <li><strong>Data Merging:</strong> Two datasets are merged on specific columns ('pdb_code', 'chain_name', 'number') to combine relevant information.</li>\n",
    "    <li><strong>Handling Missing Values:</strong> Columns and rows with excessive missing values are identified and removed to maintain data integrity.</li>\n",
    "</ul>\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
